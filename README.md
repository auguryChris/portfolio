<meta name="description" content="Repository containing portfolio of data science projects completed by me for academic, self learning, and hobby purposes." />
<meta name="title" property="og:title" content="Data Science Portfolio of Chris Westendorf" />
<meta name="image" property="og:image" content="https://drscdn.500px.org/photo/87626375/q%3D80_m%3D2000/v2?sig=2ec35eb20012d03e7e84fbdc030d356ef236a6d7af245d7e023575caff4bf912" />
<meta name="description" property="og:description" content="Repository containing portfolio of data science projects completed by me for academic, self learning, and hobby purposes." /><meta name="author" content="Chris Westendorf" />

<h1>Data Science Portfolio of Chris Westendorf</h1>
<p>Repository containing portfolio of data science projects completed by me for academic, self learning, and hobby purposes.</p>

<h2>Contents</h2>
<ul>
    <li>
        <h3>Projects</h3>
        <ul>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/micro_projects/covid-19-la/README.md">Covid-19â€™s Impact on the Value of Homes in LA:</a> Extracted millions of data points by mining real estate APIs to conduct quantitative analysis and statistical analysis of the housing market as a function of Covid-19 cases: regression, auto-correlation, frequency decomposition, rolling averages, difference in difference, causal inference.</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/micro_projects/facial_beauty_prediction/README.md">Benchmarking Facial Beauty Predictors:</a> Explored and benchmarked the visual recognition problem of Facial Beauty Prediction (FBP), assessing facial attractiveness that is consistent with human perception: feature engineering, convolution, scale-invariant feature transformations, bag of visual features term indexing and clustering, convolution neural networks, transfer learning, support vector regression, random forest regression, passive aggressive classification, partial fitting models, hyper parameter tuning.</li>
        </ul>
        <p><em>Tools: Dask, Requests, JSON, Pandas, Pickle,Time, Statistics, Aiohttp, Numpy, Altair, Plotly, Datetime, Statsmodels, CV2, Tensorflow, Sklearn, Scipy,</em></p>
    </li>
    <li>
        <h3>Data Manipulation & Mining</h3>
        <ul>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/data_manipulation/dm_metro_teams.ipynb">Wrangling Metro Sports</a>: Exposing hidden unicode during data imports. Nested functions for modular code efficiency. Correlation & T-test for a convenient data task excuse.</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/data_manipulation/dm_plotly_exploration.ipynb">Wrangling API and Location Data</a>: Import dataset, map neighborhoods, call foursquare API for nearby venues, extrapolate and resample data, create and export dataframe for downstream.</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/data_manipulation/n_grams_markov.ipynb">NLP: N-Grams & Markov</a>: Train a model to create Shakespearan Sonnets; Train a Hidden Markov Model (HMM) that is able to tag words with their part-of-speech (POS)</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/data_manipulation/time_series.ipynb">Time Series Analysis</a>: Using COVID-19 data to explore: Seasonal Decomposition, Trend Lines, Weighted Moving Averages (WMA), "Time" Exponential Moving Averages (EMA), Similarity using Euclidean Distanct, Calculate Dynamic Time Warping (DTW) Cost, Conduct Stationary Tests, Autocorrelation, Partial Autocorrelation, ARMA Forecasting, Vector Autoregresion (VAR) Forecasting, Granger Causality.</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/data_manipulation/streaming_data_mining.ipynb">Streaming Data</a>: Using a file of tweets to explore streaming data techniques: Reservoir Sampling, Counting, Bloom Filter, and a Lossy Counter.</li>
        </ul>
        <p><em>Tools: Regex, NumPy, SciPy, Pandas, Requests, DateTime, Collections, GeoPy, Folium, NLTK, Re, Statsmodels, Path, Sklearn, Math</em></p>
    </li>
    <li>
        <h3>Charting & Visualization: Exploratory Data Analysis</h3>
        <ul>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/charting_visualization/cv_altair.ipynb">Altair Plotting for Procedural Programing Access</a>: The benefit of Altair is you get to specify exact steps to get the plot you want. This gives you a lot of control and thus requires a lot of code. Fivethirtyeight replications mostly: heatmaps, bar charts, lineplots, layering & joining.</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/charting_visualization/cv_seaborn.ipynb">Searborn & MatplotLib with  US Visitation Data, Generated Samples, Student Metrics</a>: Data visualized through as QQ-plot, distribution plot, facet grid, box plot, violin plot, probability density, bar chart, line plot.</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/charting_visualization/cv_exp_plotly.ipynb">Plotly Walk Through</a>: Line chart & Scatter Mapbox Tutorial</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/charting_visualization/cv_plotly.ipynb">Exploratory Data Analysis - Plotly</a>: The journey of a quick exploratory data analysis with strava (fitness app) data: histograms, scatter plots, trendline, moving regression, violin plot, box plot, scatter mapbox.</li>
        </ul>
        <p><em>Tools: Pandas, Altair, Seaborn, MatPlotLib, Plotly Express, Datetime, NumPy, URLlib, SciPy, Math, Watermark</em></p>
    </li>
    <li>
        <h3>Big Data & Code Efficiency</h3>
        <ul>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/big_data_efficiency/bde_mrjob.ipynb">MapReduce</a>: Map Reduce to mine information from text files. MapReduce is not terribly efficient for split-apply-combine tasks when compared to Spark.</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/big_data_efficiency/bde_spark_nltk.ipynb">Spark Natural Language Tokenization</a>: Part-of-speech tagging and a super-gentle introduction to Natural Language Processing (NLP).</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/big_data_efficiency/bde_spark_yelp.ipynb">Spark RDD Using Yelp Dataset</a>: Using user defined functions to explore the 15gb yelp dataset.</li>
            <li><a href="https://github.com/auguryChris/portfolio/blob/main/big_data_efficiency/bde_spark_yelp_sql.ipynb">Spark SQL Using Yelp Dataset</a>: Using the SQL layer to wrangle 15gb of data through sql queries.</li>
        </ul>
        <p><em>Tools: MapReduce, PySpark, Regex, NLTK, Pandas</em></p>
    </li>
    <!--<li>
        <h3>Machine Learning: Supervised & Unsupervised</h3>
        <ul>
            <li></li>
        </ul>
        <p><em>Tools:</em></p>
    </li>
    <li></li>
    <li>
        <h3>Projects</h3>
        <ul>
            <li></li>
        </ul>
        <p><em>Tools:</em></p>
    </li>-->
</ul>
<h2>Getting In Touch</h2>
<!-- <p>You can find a general portfolio here.</p> -->
<p>If you liked what you saw, want to have a chat with me about the portfolio, work opportunities, or collaboration, shoot an email at westendorf {/dot/} chris {/@/} gmail.com</p>